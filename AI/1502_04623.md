DeepMind
Deep Recurrent Attentive Writer(DRAW)

foveation

MNIST
Streat View House Numbers dataset
CIFAR-10

絵を描くなど、視覚的なものを再構成することは、加工と評価を繰り返す、シーケンシャルな行い。
"one shot" approach（一発で答えを得る方法）は答えの多様性から無理。
DRAWは漸進的な方法で画像を上手く修正することに成功した。

encoder network: 画像を圧縮する
decoder network: 再構成する

stochastic gradient descent
variational auto-encoder

画像認識は一部を続けてみたり、見たい対象に注目した方が、全体を一枚の画像でみるより、よりよい情報が得られることが分かっている

難しかったところは、どこを見ればいいのかを学習させるところ。
policy gradientsを使って解決した。
reinforcement learning(強化学習)

各ステップでどこを読んで、どこになにを描くのかを決めている
Variational auto-encoderの亜種だが、違いが3つある。
* encoder/decoderでRNNを使う
* decoderの出力は毎回足されていく
* attentionメカニズムを持つ

latent distrubution
Q(Z_t|h_enc\_t)をh_enc\_tから作ったから作ったdiagonalな正規分布とする

xhat[t] = x - sigma(c[t-1])
r[t]    = read(x[t], xhat[t], hdec[t-1])
henc[t] = RNNenc(henc[t-1],[r[t], hdec[t-1]])
z[t]    ~ Q(Z[t]|henc[t])
hdec[t] = RNNdec(hdec[t-1], z[t])
c[t]    = c[t-1] + write(hdec[t])
